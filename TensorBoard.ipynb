{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0+cu101\n",
      "0.7.0+cu101\n"
     ]
    }
   ],
   "source": [
    "print (torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds,labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Network(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5)\n",
    "        self.conv2=nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5)\n",
    "        \n",
    "        self.fc1=nn.Linear(in_features=12*4*4,out_features=120)\n",
    "        self.fc2=nn.Linear(in_features=120,out_features=60)\n",
    "        self.out=nn.Linear(in_features=60,out_features=10)\n",
    "        \n",
    "    def forward(self,t):\n",
    "        t=F.relu(self.conv1(t))\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=2)\n",
    "        \n",
    "        t=F.relu(self.conv2(t))\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=2)\n",
    "        \n",
    "        t=t.flatten(start_dim=1)\n",
    "        t=F.relu(self.fc1(t))\n",
    "        \n",
    "        t=F.relu(self.fc2(t))\n",
    "        \n",
    "        t=self.out(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=torchvision.datasets.FashionMNIST(\n",
    "         root='./data'\n",
    "         ,train=True\n",
    "         ,download=True\n",
    "         ,transform=transforms.Compose([\n",
    "             transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_set,batch_size=100,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb=SummaryWriter()\n",
    "network=Network()\n",
    "images,lables=next(iter(train_loader))\n",
    "grid=torchvision.utils.make_grid(images)\n",
    "tb.add_image('images',grid)\n",
    "tb.add_graph(network,images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.01, 0.001], [10, 100, 1000], [True, False]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters=dict(\n",
    "            lr=[0.01,0.001]\n",
    "            ,batch_size=[10,100,1000]\n",
    "            ,shuffle=[True,False])\n",
    "param_values=[v for v in parameters.values()]\n",
    "param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  totalcorrect:  47610 total_loss:  3324.562201499939\n",
      "epoch  1  totalcorrect:  51578 total_loss:  2261.6957055032253\n",
      "epoch  2  totalcorrect:  52211 total_loss:  2073.266861587763\n",
      "epoch  3  totalcorrect:  52624 total_loss:  1982.511407583952\n",
      "epoch  4  totalcorrect:  52793 total_loss:  1930.6244206428528\n",
      "epoch  5  totalcorrect:  52943 total_loss:  1861.9544284045696\n",
      "epoch  6  totalcorrect:  53085 total_loss:  1822.0839728415012\n",
      "epoch  7  totalcorrect:  53305 total_loss:  1778.5763147473335\n",
      "epoch  8  totalcorrect:  53230 total_loss:  1798.454464301467\n",
      "epoch  9  totalcorrect:  53440 total_loss:  1750.819897428155\n",
      "epoch  0  totalcorrect:  53338 total_loss:  1799.2540091276169\n",
      "epoch  1  totalcorrect:  53609 total_loss:  1716.7603392153978\n",
      "epoch  2  totalcorrect:  53669 total_loss:  1698.791280835867\n",
      "epoch  3  totalcorrect:  53712 total_loss:  1686.9626589119434\n",
      "epoch  4  totalcorrect:  53741 total_loss:  1694.0613471716642\n",
      "epoch  5  totalcorrect:  53906 total_loss:  1637.0852411538363\n",
      "epoch  6  totalcorrect:  53871 total_loss:  1638.3146057277918\n",
      "epoch  7  totalcorrect:  53855 total_loss:  1669.9863778799772\n",
      "epoch  8  totalcorrect:  53933 total_loss:  1633.326772749424\n",
      "epoch  9  totalcorrect:  53889 total_loss:  1655.9536185860634\n",
      "epoch  0  totalcorrect:  53657 total_loss:  17345.351814478636\n",
      "epoch  1  totalcorrect:  53925 total_loss:  16536.625565588474\n",
      "epoch  2  totalcorrect:  54066 total_loss:  15911.360525339842\n",
      "epoch  3  totalcorrect:  53867 total_loss:  16862.134082615376\n",
      "epoch  4  totalcorrect:  54125 total_loss:  15715.44532328844\n",
      "epoch  5  totalcorrect:  54294 total_loss:  15409.607039391994\n",
      "epoch  6  totalcorrect:  54179 total_loss:  15821.339996159077\n",
      "epoch  7  totalcorrect:  54106 total_loss:  16250.63991099596\n",
      "epoch  8  totalcorrect:  54205 total_loss:  15448.704312741756\n",
      "epoch  9  totalcorrect:  54311 total_loss:  15458.697540313005\n",
      "epoch  0  totalcorrect:  54010 total_loss:  16822.421101480722\n",
      "epoch  1  totalcorrect:  54042 total_loss:  16597.63271957636\n",
      "epoch  2  totalcorrect:  54144 total_loss:  16109.34717208147\n",
      "epoch  3  totalcorrect:  54250 total_loss:  15415.301198512316\n",
      "epoch  4  totalcorrect:  54510 total_loss:  14915.763010829687\n",
      "epoch  5  totalcorrect:  54282 total_loss:  15306.810246407986\n",
      "epoch  6  totalcorrect:  54177 total_loss:  15995.418357104063\n",
      "epoch  7  totalcorrect:  54285 total_loss:  15680.50593957305\n",
      "epoch  8  totalcorrect:  54308 total_loss:  15632.975561916828\n",
      "epoch  9  totalcorrect:  54540 total_loss:  14657.884413003922\n",
      "epoch  0  totalcorrect:  53874 total_loss:  182638.65967839956\n",
      "epoch  1  totalcorrect:  54450 total_loss:  153688.08039277792\n",
      "epoch  2  totalcorrect:  54534 total_loss:  147317.1840980649\n",
      "epoch  3  totalcorrect:  54563 total_loss:  145431.88705295324\n",
      "epoch  4  totalcorrect:  54502 total_loss:  150642.5068974495\n",
      "epoch  5  totalcorrect:  54470 total_loss:  150120.1263666153\n",
      "epoch  6  totalcorrect:  54442 total_loss:  150516.46756380796\n",
      "epoch  7  totalcorrect:  54730 total_loss:  143738.68669569492\n",
      "epoch  8  totalcorrect:  54304 total_loss:  154939.47922438383\n",
      "epoch  9  totalcorrect:  54369 total_loss:  152208.69581401348\n",
      "epoch  0  totalcorrect:  54254 total_loss:  165897.18946814537\n",
      "epoch  1  totalcorrect:  54582 total_loss:  151503.3259689808\n",
      "epoch  2  totalcorrect:  54088 total_loss:  166553.08216810226\n",
      "epoch  3  totalcorrect:  54244 total_loss:  162108.67104679346\n",
      "epoch  4  totalcorrect:  54286 total_loss:  162175.06562918425\n",
      "epoch  5  totalcorrect:  54650 total_loss:  148167.52515733242\n",
      "epoch  6  totalcorrect:  52786 total_loss:  221761.89313828945\n",
      "epoch  7  totalcorrect:  54587 total_loss:  147647.8528007865\n",
      "epoch  8  totalcorrect:  54859 total_loss:  140577.42708176374\n",
      "epoch  9  totalcorrect:  54764 total_loss:  143892.4314752221\n",
      "epoch  0  totalcorrect:  55034 total_loss:  1398.1554920226336\n",
      "epoch  1  totalcorrect:  55633 total_loss:  1153.6665377020836\n",
      "epoch  2  totalcorrect:  55888 total_loss:  1071.7906926572323\n",
      "epoch  3  totalcorrect:  56003 total_loss:  1023.9097689464688\n",
      "epoch  4  totalcorrect:  56151 total_loss:  997.6522391289473\n",
      "epoch  5  totalcorrect:  56213 total_loss:  973.2776688411832\n",
      "epoch  6  totalcorrect:  56277 total_loss:  958.2530172541738\n",
      "epoch  7  totalcorrect:  56320 total_loss:  945.5819036066532\n",
      "epoch  8  totalcorrect:  56398 total_loss:  930.4158667474985\n",
      "epoch  9  totalcorrect:  56436 total_loss:  918.9779164642096\n",
      "epoch  0  totalcorrect:  56463 total_loss:  922.565689124167\n",
      "epoch  1  totalcorrect:  56483 total_loss:  897.1079692989588\n",
      "epoch  2  totalcorrect:  56567 total_loss:  882.7239991724491\n",
      "epoch  3  totalcorrect:  56627 total_loss:  871.4249974116683\n",
      "epoch  4  totalcorrect:  56630 total_loss:  864.3893241509795\n",
      "epoch  5  totalcorrect:  56670 total_loss:  856.0968390852213\n",
      "epoch  6  totalcorrect:  56682 total_loss:  849.7660341113806\n",
      "epoch  7  totalcorrect:  56692 total_loss:  846.150212418288\n",
      "epoch  8  totalcorrect:  56741 total_loss:  832.6257828995585\n",
      "epoch  9  totalcorrect:  56799 total_loss:  824.986996203661\n",
      "epoch  0  totalcorrect:  56765 total_loss:  8254.750482365489\n",
      "epoch  1  totalcorrect:  56827 total_loss:  8140.908032655716\n",
      "epoch  2  totalcorrect:  56871 total_loss:  8000.540030375123\n",
      "epoch  3  totalcorrect:  56901 total_loss:  7953.6017045378685\n",
      "epoch  4  totalcorrect:  56872 total_loss:  8014.910369366407\n",
      "epoch  5  totalcorrect:  56933 total_loss:  7942.561822943389\n",
      "epoch  6  totalcorrect:  56984 total_loss:  7780.4354801774025\n",
      "epoch  7  totalcorrect:  56955 total_loss:  7817.50498265028\n",
      "epoch  8  totalcorrect:  57017 total_loss:  7672.117720544338\n",
      "epoch  9  totalcorrect:  56974 total_loss:  7743.058857694268\n",
      "epoch  0  totalcorrect:  57007 total_loss:  7660.338703915477\n",
      "epoch  1  totalcorrect:  57000 total_loss:  7658.36554095149\n",
      "epoch  2  totalcorrect:  57059 total_loss:  7497.77406193316\n",
      "epoch  3  totalcorrect:  57127 total_loss:  7423.307038098574\n",
      "epoch  4  totalcorrect:  57088 total_loss:  7434.505326300859\n",
      "epoch  5  totalcorrect:  57175 total_loss:  7294.161145575345\n",
      "epoch  6  totalcorrect:  57143 total_loss:  7284.9788803607225\n",
      "epoch  7  totalcorrect:  57132 total_loss:  7323.625083640218\n",
      "epoch  8  totalcorrect:  57195 total_loss:  7165.907836891711\n",
      "epoch  9  totalcorrect:  57212 total_loss:  7159.054127708077\n",
      "epoch  0  totalcorrect:  57198 total_loss:  71916.57447256148\n",
      "epoch  1  totalcorrect:  57245 total_loss:  71274.0323599428\n",
      "epoch  2  totalcorrect:  57263 total_loss:  70573.4493099153\n",
      "epoch  3  totalcorrect:  57243 total_loss:  70616.9089563191\n",
      "epoch  4  totalcorrect:  57255 total_loss:  70899.40415509045\n",
      "epoch  5  totalcorrect:  57307 total_loss:  68782.22841210663\n",
      "epoch  6  totalcorrect:  57259 total_loss:  71433.73593874276\n",
      "epoch  7  totalcorrect:  57297 total_loss:  70973.88804517686\n",
      "epoch  8  totalcorrect:  57391 total_loss:  67685.40899083018\n",
      "epoch  9  totalcorrect:  57358 total_loss:  67869.43918280303\n",
      "epoch  0  totalcorrect:  57348 total_loss:  68605.93764483929\n",
      "epoch  1  totalcorrect:  57392 total_loss:  67426.14438384771\n",
      "epoch  2  totalcorrect:  57316 total_loss:  68888.58428224921\n",
      "epoch  3  totalcorrect:  57400 total_loss:  66565.5665602535\n",
      "epoch  4  totalcorrect:  57403 total_loss:  66633.28122347593\n",
      "epoch  5  totalcorrect:  57431 total_loss:  65886.62264216691\n",
      "epoch  6  totalcorrect:  57453 total_loss:  65792.10233874619\n",
      "epoch  7  totalcorrect:  57492 total_loss:  65445.467008277774\n",
      "epoch  8  totalcorrect:  57445 total_loss:  65800.08081533015\n",
      "epoch  9  totalcorrect:  57427 total_loss:  66862.44725994766\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "lr=0.01\n",
    "\n",
    "network=Network()\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
    "images,lables=next(iter(train_loader))\n",
    "grid=torchvision.utils.make_grid(images)\n",
    "for lr,batch_size,shuffle in product(*param_values):\n",
    "    \n",
    "    optimizer=optim.Adam(network.parameters(),lr=lr)    \n",
    "    comment=f'batch_size= {batch_size} lr={lr}'\n",
    "    tb=SummaryWriter(comment=comment)\n",
    "    tb.add_image('images',grid)\n",
    "    tb.add_graph(network,images)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        total_loss=0\n",
    "        total_correct=0\n",
    "        for batch in train_loader:\n",
    "            images,labels=batch\n",
    "\n",
    "            preds=network(images)\n",
    "            loss=F.cross_entropy(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss+=loss.item()* batch_size\n",
    "            total_correct+=get_num_correct(preds,labels)\n",
    "\n",
    "        tb.add_scalar(\"Loss \",total_loss,epoch)\n",
    "        tb.add_scalar(\"Number Correct \",total_correct,epoch)\n",
    "        tb.add_scalar(\"Accuracy \",total_correct/len(train_set),epoch)\n",
    "\n",
    "        #tb.add_histogram(\"conv1.bias \",network.conv1.bias,epoch)\n",
    "        #tb.add_histogram(\"conv1.weight\", network.conv1.weight,epoch)\n",
    "        #tb.add_histogram(\"conv1.weight.grad\", network.conv1.weight.grad,epoch)\n",
    "\n",
    "        for name,weight in network.named_parameters():\n",
    "            tb.add_histogram(name,weight,epoch)\n",
    "            tb.add_histogram(f'{name}.grad',weight.grad,epoch)\n",
    "\n",
    "        print(\"epoch \",epoch, \" totalcorrect: \",total_correct, \"total_loss: \",total_loss)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
